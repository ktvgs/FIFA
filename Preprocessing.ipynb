{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4793f6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dheer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dheer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Load the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9960d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>english_only_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@evanderkoogh Carry on sir x</td>\n",
       "      <td>evanderkoogh carri sir x</td>\n",
       "      <td>sir x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Me at 8:30 Sunday - Thursday #LoveIslandAU #dr...</td>\n",
       "      <td>sunday thursday loveislandau dramaisland http</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eso demuestra que es una MUJER que se hace res...</td>\n",
       "      <td>eso demuestra que es una mujer que se hace res...</td>\n",
       "      <td>es se con se manipular el de la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Place based community led service development ...</td>\n",
       "      <td>place base commun led servic develop address d...</td>\n",
       "      <td>place base led develop address ill health need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@lunachrissy  https://t.co/5NdeBckTZz</td>\n",
       "      <td>lunachrissi http</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                       @evanderkoogh Carry on sir x   \n",
       "1  Me at 8:30 Sunday - Thursday #LoveIslandAU #dr...   \n",
       "2  Eso demuestra que es una MUJER que se hace res...   \n",
       "3  Place based community led service development ...   \n",
       "4              @lunachrissy  https://t.co/5NdeBckTZz   \n",
       "\n",
       "                                      processed_text  \\\n",
       "0                           evanderkoogh carri sir x   \n",
       "1      sunday thursday loveislandau dramaisland http   \n",
       "2  eso demuestra que es una mujer que se hace res...   \n",
       "3  place base commun led servic develop address d...   \n",
       "4                                   lunachrissi http   \n",
       "\n",
       "                                   english_only_text  \n",
       "0                                              sir x  \n",
       "1                                                     \n",
       "2                    es se con se manipular el de la  \n",
       "3  place base led develop address ill health need...  \n",
       "4                                                     "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb34b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37229422",
   "metadata": {},
   "outputs": [],
   "source": [
    "country1=[]\n",
    "dataset='Nigeria_tweets_of_interest.csv'\n",
    "with open(dataset,encoding=\"utf-8\") as file:\n",
    "    \n",
    "    for line in file:\n",
    "        country1.append(line.split('|@|||$|')[2])\n",
    "df1=pd.DataFrame(country1,columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b620ff51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(666103, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4303127a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['processed_text'] = df1['text'].apply(preprocess_text)\n",
    "\n",
    "# Filter out non-English words using NLTK's English word corpus\n",
    "english_words = set(nltk.corpus.words.words())\n",
    "df1['english_only_text'] = df1['processed_text'].apply(lambda x: ' '.join(w for w in x.split() if w in english_words))\n",
    "df1=df1[df1['english_only_text']!=\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "558a1450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>english_only_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jackdre02 Na code na them nor wan spend money</td>\n",
       "      <td>na code na wan spend money</td>\n",
       "      <td>na code na wan spend money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A whole Argentina ðŸ˜©ðŸ˜©ðŸ˜©ðŸ˜©ðŸ˜©</td>\n",
       "      <td>whole argentina</td>\n",
       "      <td>whole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bye Bye Argentina   Nigeria Super Eagles over ...</td>\n",
       "      <td>bye bye argentina nigeria super eagl thenff wo...</td>\n",
       "      <td>bye bye super</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BREAKING NEWS: Messi on the next flight to Spain.</td>\n",
       "      <td>break news messi next flight spain</td>\n",
       "      <td>break news next flight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The highest embarrassment ever!! 3 nil!! Jesus...</td>\n",
       "      <td>highest embarrass ever nil jesu christ argenti...</td>\n",
       "      <td>highest embarrass ever nil wast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Not bad but i'll pass https://t.co/xJuNLjo8ph</td>\n",
       "      <td>bad pass http</td>\n",
       "      <td>bad pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Humiliation goal  Argentina ðŸ‡¦ðŸ‡· 0 v Croatia ðŸ‡­ðŸ‡· ...</td>\n",
       "      <td>humili goal argentina v croatia worldcup</td>\n",
       "      <td>goal v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Messi is retiring for real after this.</td>\n",
       "      <td>messi retir real</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LMAO lowkey I like the line sha https://t.co/A...</td>\n",
       "      <td>lmao lowkey like line sha http</td>\n",
       "      <td>like line sha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Under your asun watch with captain band Croati...</td>\n",
       "      <td>asun watch captain band croatia argentina worl...</td>\n",
       "      <td>watch captain band</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "1      @jackdre02 Na code na them nor wan spend money   \n",
       "3                             A whole Argentina ðŸ˜©ðŸ˜©ðŸ˜©ðŸ˜©ðŸ˜©   \n",
       "4   Bye Bye Argentina   Nigeria Super Eagles over ...   \n",
       "5   BREAKING NEWS: Messi on the next flight to Spain.   \n",
       "6   The highest embarrassment ever!! 3 nil!! Jesus...   \n",
       "7       Not bad but i'll pass https://t.co/xJuNLjo8ph   \n",
       "10  Humiliation goal  Argentina ðŸ‡¦ðŸ‡· 0 v Croatia ðŸ‡­ðŸ‡· ...   \n",
       "11             Messi is retiring for real after this.   \n",
       "12  LMAO lowkey I like the line sha https://t.co/A...   \n",
       "13  Under your asun watch with captain band Croati...   \n",
       "\n",
       "                                       processed_text  \\\n",
       "1                          na code na wan spend money   \n",
       "3                                     whole argentina   \n",
       "4   bye bye argentina nigeria super eagl thenff wo...   \n",
       "5                  break news messi next flight spain   \n",
       "6   highest embarrass ever nil jesu christ argenti...   \n",
       "7                                       bad pass http   \n",
       "10           humili goal argentina v croatia worldcup   \n",
       "11                                   messi retir real   \n",
       "12                     lmao lowkey like line sha http   \n",
       "13  asun watch captain band croatia argentina worl...   \n",
       "\n",
       "                  english_only_text  \n",
       "1        na code na wan spend money  \n",
       "3                             whole  \n",
       "4                     bye bye super  \n",
       "5            break news next flight  \n",
       "6   highest embarrass ever nil wast  \n",
       "7                          bad pass  \n",
       "10                           goal v  \n",
       "11                             real  \n",
       "12                    like line sha  \n",
       "13               watch captain band  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53084cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(539685, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfd88eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df1['english_only_text']).to_csv('nigeria_pp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7a14fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df['english_only_text']).to_csv('australia_pp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8f0c7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "country=[]\n",
    "dataset='Denmark_tweets_of_interest.csv'\n",
    "with open(dataset,encoding=\"utf-8\") as file:\n",
    "    \n",
    "    for line in file:\n",
    "        country.append(line.split('|@|||$|')[2])\n",
    "df=pd.DataFrame(country,columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf23d9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function to preprocess text data\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text into individual words\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove non-alphabetic characters and convert to lowercase\n",
    "    clean_tokens = [token.lower() for token in tokens if token.isalpha()]\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [token for token in clean_tokens if not token in stop_words]\n",
    "    \n",
    "    # Stem the remaining words using Porter stemmer\n",
    "    ps = PorterStemmer()\n",
    "    stemmed_tokens = [ps.stem(token) for token in filtered_tokens]\n",
    "    \n",
    "    # Join the stemmed tokens back into a single string\n",
    "    processed_text = ' '.join(stemmed_tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Apply the preprocessing function to the text column\n",
    "df['processed_text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "# Filter out non-English words using NLTK's English word corpus\n",
    "english_words = set(nltk.corpus.words.words())\n",
    "df['english_only_text'] = df['processed_text'].apply(lambda x: ' '.join(w for w in x.split() if w in english_words))\n",
    "df=df[df['english_only_text']!=\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c1f10c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>english_only_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fredagens glade budskab skriver @Landdistrikte...</td>\n",
       "      <td>fredagen glade budskab skriver landdistrikt og...</td>\n",
       "      <td>glade til de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@steph93065 @realDonaldTrump Big parts of the ...</td>\n",
       "      <td>realdonaldtrump big part world find separ abom...</td>\n",
       "      <td>big part world find million live bad sad kidna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fredagens glade budskab skriver @Landdistrikte...</td>\n",
       "      <td>fredagen glade budskab skriver landdistrikt og...</td>\n",
       "      <td>glade til de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@captlmcook30 @SteveSchmidtSES As a woman, a p...</td>\n",
       "      <td>steveschmidts woman person mix race famili mem...</td>\n",
       "      <td>woman person mix race member could agre r crus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wind 0,0 m/s ---. Barometer 1013,18 hPa, Stead...</td>\n",
       "      <td>wind baromet hpa steadi temperatur rain today ...</td>\n",
       "      <td>wind rain today humid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Fredagens glade budskab skriver @Landdistrikte...   \n",
       "1  @steph93065 @realDonaldTrump Big parts of the ...   \n",
       "2  Fredagens glade budskab skriver @Landdistrikte...   \n",
       "3  @captlmcook30 @SteveSchmidtSES As a woman, a p...   \n",
       "4  Wind 0,0 m/s ---. Barometer 1013,18 hPa, Stead...   \n",
       "\n",
       "                                      processed_text  \\\n",
       "0  fredagen glade budskab skriver landdistrikt og...   \n",
       "1  realdonaldtrump big part world find separ abom...   \n",
       "2  fredagen glade budskab skriver landdistrikt og...   \n",
       "3  steveschmidts woman person mix race famili mem...   \n",
       "4  wind baromet hpa steadi temperatur rain today ...   \n",
       "\n",
       "                                   english_only_text  \n",
       "0                                       glade til de  \n",
       "1  big part world find million live bad sad kidna...  \n",
       "2                                       glade til de  \n",
       "3  woman person mix race member could agre r crus...  \n",
       "4                              wind rain today humid  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc4a3459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50378, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c16a29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('denmark_pp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de79486a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
